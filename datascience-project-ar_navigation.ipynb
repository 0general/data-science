{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "rpath = 'r_data'\n",
    "fpath = 'validation'\n",
    "transform_train = transforms.Compose([ transforms.ToTensor(),transforms.Resize((224,224))])\n",
    "\n",
    "train_dataset = ImageFolder(root=rpath, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4,shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder(root=fpath, transform=transform_train)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle = False)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = models.vgg16(pretrained=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.0000015)\n",
    "save_path='weight'\n",
    "net.classifier._modules['6'] = nn.Linear(4096, 4)\n",
    "net.to(device)\n",
    "print(net)\n",
    "\n",
    "res=[]\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    l = []\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs= net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 40 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / (i+1)))\n",
    "            l.append([epoch + 1, i + 1, running_loss / (i+1)])\n",
    "            running_loss = 0.0\n",
    "    res.append(l)\n",
    "\n",
    "\n",
    "    torch.save(net.state_dict(), save_path)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "\n",
    "net.load_state_dict(torch.load(save_path))\n",
    "net.to(device)\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "accuracy_sum=0\n",
    "lab = [\"burgerking\",'cu','gs25','lotteria']\n",
    "for i in range(4):\n",
    "    temp = 100 * class_correct[i] / class_total[i]\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        lab[i], temp))\n",
    "    accuracy_sum+=temp\n",
    "print('Accuracy average: ', accuracy_sum/4)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
